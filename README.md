# U.S. Dive Sites ETL #
There is a lot of very important and useful data available these days, but it is often dispersed among multiple data sources and not well organized. Extracting the data from it's sources, transforming it by cleaning or reformatting it, and loading or storing the resulting data into a well designed database is a critical process for data-driven organizations. This process is referred to as ETL.

## Background ## 
Data about dive sites in the United States, along with information about the weather, tides, and any wrecks or obstructions at the dive site will be extracted from multiple sources. The data will then be transformed to ensure only relevant data from each of the sources makes it into the final database. Once the data is cleaned, and properly formatted, it will be loaded into a SQL Database in PostgreSQL. 

This database is meant to cater to diving companies, as well as independent divers that are planning future excursions within the U.S. to assist in a search to find the perfect diving location.

## Data Sources ## 
* [Dive Sites API](http://api.divesites.com/docs/)
* [Weather API](https://openweathermap.org/api)
* [Tides and Currents API](https://tidesandcurrents.noaa.gov/web_services_info.html)
* [Wrecks and Obstructions Database](https://nauticalcharts.noaa.gov/data/wrecks-and-obstructions.html)

#### Status #### 
This project is *in progress*. 

#### Contact #### 
[Tyler Brown](https://github.com/Starcode897)  
[William Rosen](https://github.com/wrosen07)  
[Buddy Slater](https://github.com/jtslater2)  
[Jessy Thomas](https://github.com/jethomas2020)  
[Chloe Veras](https://github.com/cveras33)
